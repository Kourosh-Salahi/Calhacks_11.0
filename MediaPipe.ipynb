{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 1,
=======
   "execution_count": 4,
>>>>>>> 1a793967dcb433090f92a6009357e683c2389a49
   "id": "93e2d637-7571-40d4-8dc6-d9177571c115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\python312\\lib\\site-packages (4.10.0.84)\n",
      "Collecting mediapipe\n",
      "  Using cached mediapipe-0.10.14-cp312-cp312-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: msvc-runtime in c:\\python312\\lib\\site-packages (14.40.33807)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\python312\\lib\\site-packages (from opencv-python) (2.0.0)\n",
      "Collecting absl-py (from mediapipe)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting attrs>=19.1.0 (from mediapipe)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\python312\\lib\\site-packages (from mediapipe) (24.3.25)\n",
      "Collecting jax (from mediapipe)\n",
      "  Using cached jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting jaxlib (from mediapipe)\n",
      "  Using cached jaxlib-0.4.34-cp312-cp312-win_amd64.whl.metadata (1.0 kB)\n",
      "Collecting matplotlib (from mediapipe)\n",
      "  Using cached matplotlib-3.9.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\python312\\lib\\site-packages (from mediapipe) (4.10.0.84)\n",
      "Requirement already satisfied: protobuf<5,>=4.25.3 in c:\\python312\\lib\\site-packages (from mediapipe) (4.25.3)\n",
      "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
      "  Using cached sounddevice-0.5.1-py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe)\n",
      "  Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\python312\\lib\\site-packages (from jax->mediapipe) (0.5.0)\n",
      "Requirement already satisfied: opt-einsum in c:\\python312\\lib\\site-packages (from jax->mediapipe) (3.4.0)\n",
      "Requirement already satisfied: scipy>=1.10 in c:\\python312\\lib\\site-packages (from jax->mediapipe) (1.14.1)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->mediapipe)\n",
      "  Using cached contourpy-1.3.0-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->mediapipe)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python312\\lib\\site-packages (from matplotlib->mediapipe) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python312\\lib\\site-packages (from matplotlib->mediapipe) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from matplotlib->mediapipe) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\python312\\lib\\site-packages (from matplotlib->mediapipe) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python312\\lib\\site-packages (from matplotlib->mediapipe) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kouro\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
      "Requirement already satisfied: pycparser in c:\\python312\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Using cached mediapipe-0.10.14-cp312-cp312-win_amd64.whl (50.8 MB)\n",
      "Using cached attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Using cached sounddevice-0.5.1-py3-none-win_amd64.whl (363 kB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached jax-0.4.34-py3-none-any.whl (2.1 MB)\n",
      "Using cached jaxlib-0.4.34-cp312-cp312-win_amd64.whl (55.3 MB)\n",
      "Using cached matplotlib-3.9.2-cp312-cp312-win_amd64.whl (7.8 MB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Using cached contourpy-1.3.0-cp312-cp312-win_amd64.whl (218 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Installing collected packages: cycler, contourpy, CFFI, attrs, absl-py, sounddevice, matplotlib, jaxlib, jax, mediapipe\n",
      "Successfully installed CFFI-1.17.1 absl-py-2.1.0 attrs-24.2.0 contourpy-1.3.0 cycler-0.12.1 jax-0.4.34 jaxlib-0.4.34 matplotlib-3.9.2 mediapipe-0.10.14 sounddevice-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (c:\\Python312\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "pip install opencv-python mediapipe msvc-runtime"
=======
    "%pip install --user opencv-python mediapipe msvc-runtime\n"
>>>>>>> 1a793967dcb433090f92a6009357e683c2389a49
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 2,
=======
   "execution_count": 9,
>>>>>>> 1a793967dcb433090f92a6009357e683c2389a49
   "id": "04e2a2ee-27f2-4c55-8cea-b503fc3592ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 10,
>>>>>>> 1a793967dcb433090f92a6009357e683c2389a49
   "id": "6c8f5226-a390-4742-ac77-da7e2f25a0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the Holistic Model from Mediapipe and\n",
    "# Initializing the Model\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic_model = mp_holistic.Holistic(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    " \n",
    "# Initializing the drawing utils for drawing the facial landmarks on image\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3363dc-e88d-414f-8c38-6db5d64a60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(joint, x, y, z)\n",
    "import cv2\n",
    "import time\n",
    "import mediapipe as mp\n",
    "\n",
    "# Initialize MediaPipe components\n",
    "mp_holistic = mp.solutions.holistic\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# Create a holistic model instance\n",
    "holistic_model = mp_holistic.Holistic()\n",
    "\n",
    "# (0) in VideoCapture is used to connect to your computer's default camera\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while capture.isOpened():\n",
    "    # Capture frame by frame\n",
    "    ret, frame = capture.read()\n",
    "\n",
    "    # Converting the frame from BGR to RGB\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Making predictions using holistic model\n",
    "    image.flags.writeable = False\n",
    "    results = holistic_model.process(image)\n",
    "    image.flags.writeable = True\n",
    "\n",
    "    hand_joints = []\n",
    "\n",
    "    # Extracting right hand landmarks if available\n",
    "    if results.right_hand_landmarks:\n",
    "        right_hand_joints = []\n",
    "        for id, lm in enumerate(results.right_hand_landmarks.landmark):\n",
    "            right_hand_joints.append((id, lm.x, lm.y, lm.z))  # Store the landmark ID and normalized coordinates\n",
    "        print(\"Right Hand Joints:\", right_hand_joints)\n",
    "\n",
    "    # Extracting left hand landmarks if available\n",
    "    if results.left_hand_landmarks:\n",
    "        left_hand_joints = []\n",
    "        for id, lm in enumerate(results.left_hand_landmarks.landmark):\n",
    "            left_hand_joints.append((id, lm.x, lm.y, lm.z))  # Store the landmark ID and normalized coordinates\n",
    "        print(\"Left Hand Joints:\", left_hand_joints)\n",
    "\n",
    "    # Enter key 'q' to break the loop\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# When all the process is done\n",
    "# Release the capture\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0638990b-7690-4047-aad0-c1f1742852f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code to access landmarks\n",
    "for landmark in mp_holistic.HandLandmark:\n",
    "    print(landmark, landmark.value)\n",
    " \n",
    "print(mp_holistic.HandLandmark.WRIST.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39760323-6778-4c46-8f04-9618bd2bbf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from groq import Groq\n",
    "\n",
    "content = \"\\n\\neach of these points is a number followed by a 3 dimensional vector in space (number, x, y, z), each of the numbers corresponds to a joint on the hand. \\n\\n0. WRIST 1. THUMB_CMC 2. THUMB_MCP  3. THUMB_IP 4. THUMB_TIP 5. INDEX FINGER_MCP 6. INDEX FINGER PIP 7. INDEX FINGER_DIP 8. INDEX FINGER TIP 9. MIDDLE FINGER_MCP 10. MIDDLE FINGER_PIP 11. MIDDLE FINGER DIP 12. MIDDLE FINGER TIP 13. RING FINGER MCP 14. RING FINGER PIP 15. RING FINGER_DIP 16. RING FINGER TIP 17. PINKY MCP 18. PINKY PIP 19. PINKY DIP 20. PINKY TIP\\n\\nwhat ASL letter does this create\"\"\n",
    "\n",
    "\n",
    "\n",
    "GROQ_API_KEY = \"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\"\n",
    "client = Groq(api_key=GROQ_API_KEY)\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"llama-3.2-90b-vision-preview\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"(0, 0.6291446685791016, 0.7474343180656433, -6.940783805475803e-07)\\t(1, 0.569800078868866, 0.6609311103820801, 0.0010792140383273363)\\t(2, 0.539739191532135, 0.5481612682342529, 0.003179557854309678)\\t(3, 0.5340869426727295, 0.45456331968307495, -0.0023627004120498896)\\t(4, 0.5218374729156494, 0.37604692578315735, -0.006354242563247681)\\t(5, 0.5817943215370178, 0.47687196731567383, 0.03281461074948311)\\t(6, 0.5637698769569397, 0.40330374240875244, 0.004460983909666538)\\t(7, 0.5551409721374512, 0.47667184472084045, -0.016215043142437935)\\t(8, 0.5547307729721069, 0.548344075679779, -0.024093450978398323\\t(9, 0.6133684515953064, 0.48441281914711, 0.02117038145661354)\\t(10, 0.5906840562820435, 0.40759730339050293, -0.009866598062217236\\t(11, 0.5814631581306458, 0.5008186101913452, -0.023821111768484116)\\t(12, 0.5828279256820679, 0.5740489363670349, -0.023433201014995575\\t(13, 0.6476872563362122, 0.4972296953201294, 0.0041257343254983425)\\t(14, 0.6219602823257446, 0.42597198486328125, -0.024648429825901985)\\t(15, 0.6111117005348206, 0.5210391283035278, -0.021492788568139076)\\t(16, 0.6128002405166626, 0.5899154543876648, -0.008664877153933048)\\t(17, 0.6863601803779602, 0.5180871486663818, -0.0135530736297369)\\t(18, 0.6599762439727783, 0.45347484946250916, -0.02926407940685749)\\t(19, 0.6488719582557678, 0.5114790201187134, -0.021297810599207878)\\t(20, 0.6518837213516235, 0.5598867535591125, -0.00871617253869772)\\n\\neach of these points is a number followed by a 3 dimensional vector in space (number, x, y, z), each of the numbers corresponds to a joint on the hand. \\n\\n0. WRIST 1. THUMB_CMC 2. THUMB_MCP  3. THUMB_IP 4. THUMB_TIP 5. INDEX FINGER_MCP 6. INDEX FINGER PIP 7. INDEX FINGER_DIP 8. INDEX FINGER TIP 9. MIDDLE FINGER_MCP 10. MIDDLE FINGER_PIP 11. MIDDLE FINGER DIP 12. MIDDLE FINGER TIP 13. RING FINGER MCP 14. RING FINGER PIP 15. RING FINGER_DIP 16. RING FINGER TIP 17. PINKY MCP 18. PINKY PIP 19. PINKY DIP 20. PINKY TIP\\n\\nwhat ASL letter does this create\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=1024,\n",
    "    top_p=1,\n",
    "    stream=False,\n",
    "    stop=None,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b224b585-6d68-4738-91da-27281a9ee900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # base\n",
    "# # (0) in VideoCapture is used to connect to your computer's default camera\n",
    "# capture = cv2.VideoCapture(0)\n",
    "\n",
    "# # Initializing current time and precious time for calculating the FPS\n",
    "# previousTime = 0\n",
    "# currentTime = 0\n",
    "\n",
    "# while capture.isOpened():\n",
    "# \t# capture frame by frame\n",
    "# \tret, frame = capture.read()\n",
    "\n",
    "# \t# resizing the frame for better view\n",
    "# \tframe = cv2.resize(frame, (800, 600))\n",
    "\n",
    "# \t# Converting the from BGR to RGB\n",
    "# \timage = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# \t# Making predictions using holistic model\n",
    "# \t# To improve performance, optionally mark the image as not writeable to\n",
    "# \t# pass by reference.\n",
    "# \timage.flags.writeable = False\n",
    "# \tresults = holistic_model.process(image)\n",
    "# \timage.flags.writeable = True\n",
    "\n",
    "# \t# Converting back the RGB image to BGR\n",
    "# \timage = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# \t# Drawing the Facial Landmarks\n",
    "# \tmp_drawing.draw_landmarks(\n",
    "# \timage,\n",
    "# \tresults.face_landmarks,\n",
    "# \tmp_holistic.FACEMESH_CONTOURS,\n",
    "# \tmp_drawing.DrawingSpec(\n",
    "# \t\tcolor=(255,0,255),\n",
    "# \t\tthickness=1,\n",
    "# \t\tcircle_radius=1\n",
    "# \t),\n",
    "# \tmp_drawing.DrawingSpec(\n",
    "# \t\tcolor=(0,255,255),\n",
    "# \t\tthickness=1,\n",
    "# \t\tcircle_radius=1\n",
    "# \t)\n",
    "# \t)\n",
    "\n",
    "# \t# Drawing Right hand Land Marks\n",
    "# \tmp_drawing.draw_landmarks(\n",
    "# \timage, \n",
    "# \tresults.right_hand_landmarks, \n",
    "# \tmp_holistic.HAND_CONNECTIONS\n",
    "# \t)\n",
    "\n",
    "# \t# Drawing Left hand Land Marks\n",
    "# \tmp_drawing.draw_landmarks(\n",
    "# \timage, \n",
    "# \tresults.left_hand_landmarks, \n",
    "# \tmp_holistic.HAND_CONNECTIONS\n",
    "# \t)\n",
    "\t\n",
    "# \t# Calculating the FPS\n",
    "# \tcurrentTime = time.time()\n",
    "# \tfps = 1 / (currentTime-previousTime)\n",
    "# \tpreviousTime = currentTime\n",
    "\t\n",
    "# \t# Displaying FPS on the image\n",
    "# \tcv2.putText(image, str(int(fps))+\" FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "# \t# Display the resulting image\n",
    "# \tcv2.imshow(\"Facial and Hand Landmarks\", image)\n",
    "\n",
    "# \t# Enter key 'q' to break the loop\n",
    "# \tif cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "# \t\tbreak\n",
    "\n",
    "# # When all the process is done\n",
    "# # Release the capture and destroy all windows\n",
    "# capture.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6406134-e4b5-4ec2-baba-a9a2524baf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with different colors\n",
    "# import cv2\n",
    "# import mediapipe as mp\n",
    "# import time\n",
    "# import numpy as np\n",
    "\n",
    "# # Initializing mediapipe modules\n",
    "# mp_holistic = mp.solutions.holistic\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# # Initialize holistic model\n",
    "# holistic_model = mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5)\n",
    "\n",
    "# # (0) in VideoCapture is used to connect to your computer's default camera\n",
    "# capture = cv2.VideoCapture(0)\n",
    "\n",
    "# # Initializing current time and previous time for calculating the FPS\n",
    "# previousTime = 0\n",
    "\n",
    "# # Define a list of 21 different colors for each hand landmark\n",
    "# colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255), \n",
    "#           (0, 255, 255), (128, 0, 0), (0, 128, 0), (0, 0, 128), (128, 128, 0),\n",
    "#           (128, 0, 128), (0, 128, 128), (255, 128, 0), (255, 0, 128), (128, 255, 0),\n",
    "#           (0, 255, 128), (128, 0, 255), (0, 128, 255), (255, 128, 128), (128, 255, 128),\n",
    "#           (128, 128, 255)]\n",
    "\n",
    "# while capture.isOpened():\n",
    "#     # Capture frame by frame\n",
    "#     ret, frame = capture.read()\n",
    "\n",
    "#     # Resizing the frame for better view\n",
    "#     frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "#     # Converting the from BGR to RGB\n",
    "#     image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     # Making predictions using holistic model\n",
    "#     image.flags.writeable = False\n",
    "#     results = holistic_model.process(image)\n",
    "#     image.flags.writeable = True\n",
    "\n",
    "#     # Converting back the RGB image to BGR\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#     # If landmarks are detected on the right hand\n",
    "#     if results.right_hand_landmarks:\n",
    "#         # Loop through each landmark point\n",
    "#         for idx, landmark in enumerate(results.right_hand_landmarks.landmark):\n",
    "#             # Get landmark coordinates\n",
    "#             h, w, c = image.shape\n",
    "#             cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "\n",
    "#             # Draw circle for each landmark with a different color\n",
    "#             cv2.circle(image, (cx, cy), 7, colors[idx], cv2.FILLED)\n",
    "\n",
    "#         # Optionally, draw hand connections (in a single color if desired)\n",
    "#         mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "#     # Similarly, you can do this for the left hand\n",
    "#     if results.left_hand_landmarks:\n",
    "#         for idx, landmark in enumerate(results.left_hand_landmarks.landmark):\n",
    "#             h, w, c = image.shape\n",
    "#             cx, cy = int(landmark.x * w), int(landmark.y * h)\n",
    "#             cv2.circle(image, (cx, cy), 7, colors[idx], cv2.FILLED)\n",
    "\n",
    "#         mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "#     # Calculating the FPS\n",
    "#     currentTime = time.time()\n",
    "#     fps = 1 / (currentTime - previousTime)\n",
    "#     previousTime = currentTime\n",
    "\n",
    "#     # Displaying FPS on the image\n",
    "#     cv2.putText(image, str(int(fps)) + \" FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "#     # Display the resulting image\n",
    "#     cv2.imshow(\"Hand Landmarks with Different Colors\", image)\n",
    "\n",
    "#     # Enter key 'q' to break the loop\n",
    "#     if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # Release the capture and destroy all windows\n",
    "# capture.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "id": "e6854e3f-8395-4aaa-ac8c-8ca8a9e57bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
=======
   "execution_count": 12,
   "id": "e6854e3f-8395-4aaa-ac8c-8ca8a9e57bd1",
   "metadata": {},
   "outputs": [],
>>>>>>> 1a793967dcb433090f92a6009357e683c2389a49
   "source": [
    "# # hands with numbers\n",
    "# import cv2\n",
    "# import time\n",
    "# import mediapipe as mp\n",
    "\n",
    "# # Initialize MediaPipe components\n",
    "# mp_holistic = mp.solutions.holistic\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# # Create a holistic model instance\n",
    "# holistic_model = mp_holistic.Holistic()\n",
    "\n",
    "# # (0) in VideoCapture is used to connect to your computer's default camera\n",
    "# capture = cv2.VideoCapture(0)\n",
    "\n",
    "# # Initializing current time and previous time for calculating the FPS\n",
    "# previousTime = 0\n",
    "# currentTime = 0\n",
    "\n",
    "# while capture.isOpened():\n",
    "#     # Capture frame by frame\n",
    "#     ret, frame = capture.read()\n",
    "\n",
    "#     # Resizing the frame for better view\n",
    "#     frame = cv2.resize(frame, (800, 600))\n",
    "\n",
    "#     # Converting the frame from BGR to RGB\n",
    "#     image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     # Making predictions using holistic model\n",
    "#     image.flags.writeable = False\n",
    "#     results = holistic_model.process(image)\n",
    "#     image.flags.writeable = True\n",
    "\n",
    "#     # Converting back the RGB image to BGR\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "#     # Drawing Right hand Landmarks\n",
    "#     if results.right_hand_landmarks:\n",
    "#         mp_drawing.draw_landmarks(\n",
    "#             image,\n",
    "#             results.right_hand_landmarks,\n",
    "#             mp_holistic.HAND_CONNECTIONS\n",
    "#         )\n",
    "#         # Adding landmark numbers to right hand\n",
    "#         for id, lm in enumerate(results.right_hand_landmarks.landmark):\n",
    "#             h, w, _ = image.shape\n",
    "#             cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "#             cv2.circle(image, (cx, cy), 5, (0, 0, 255), -1)  # Red circle for landmarks\n",
    "#             cv2.putText(image, str(id), (cx, cy - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 255), 1)  # Label each landmark\n",
    "\n",
    "#     # Drawing Left hand Landmarks\n",
    "#     if results.left_hand_landmarks:\n",
    "#         mp_drawing.draw_landmarks(\n",
    "#             image,\n",
    "#             results.left_hand_landmarks,\n",
    "#             mp_holistic.HAND_CONNECTIONS\n",
    "#         )\n",
    "#         # Adding landmark numbers to left hand\n",
    "#         for id, lm in enumerate(results.left_hand_landmarks.landmark):\n",
    "#             h, w, _ = image.shape\n",
    "#             cx, cy = int(lm.x * w), int(lm.y * h)\n",
    "#             cv2.circle(image, (cx, cy), 5, (0, 0, 255), -1)  # Red circle for landmarks\n",
    "#             cv2.putText(image, str(id), (cx, cy - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (255, 255, 255), 1)  # Label each landmark\n",
    "\n",
    "#     # Calculating the FPS\n",
    "#     currentTime = time.time()\n",
    "#     fps = 1 / (currentTime - previousTime)\n",
    "#     previousTime = currentTime\n",
    "\n",
    "#     # Displaying FPS on the image\n",
    "#     cv2.putText(image, str(int(fps)) + \" FPS\", (10, 70), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "#     # Display the resulting image\n",
    "#     cv2.imshow(\"Facial and Hand Landmarks\", image)\n",
    "\n",
    "#     # Enter key 'q' to break the loop\n",
    "#     if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# # When all the process is done\n",
    "# # Release the capture and destroy all windows\n",
    "# capture.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
